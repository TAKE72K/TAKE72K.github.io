<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on 竹林七閑</title>
    <link>https://take72k.github.io/tags/AI/</link>
    <description>Recent content in AI on 竹林七閑</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-tw</language>
    <lastBuildDate>Thu, 03 Nov 2022 21:01:00 +0800</lastBuildDate><atom:link href="https://take72k.github.io/tags/AI/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chip Placement with Deep Reinforcement Learning 閱讀筆記</title>
      <link>https://take72k.github.io/EDA/placementByRL/</link>
      <pubDate>Thu, 03 Nov 2022 21:01:00 +0800</pubDate>
      
      <guid>https://take72k.github.io/EDA/placementByRL/</guid>
      <description>《基於深度強化學習的晶片擺置》 閱讀筆記 link 引言 《基於深度強化學習的晶片擺置》 Google這篇一出可說語驚四座，從未有人把強化學習拿來擺phys</description>
    </item>
    
    <item>
      <title># fatal error: FreeImage.h: No such file or directory #include “FreeImage.h” CentOS 7</title>
      <link>https://take72k.github.io/EDA/cudnnSetup/</link>
      <pubDate>Wed, 10 Aug 2022 05:20:00 +0800</pubDate>
      
      <guid>https://take72k.github.io/EDA/cudnnSetup/</guid>
      <description>fatal error: FreeImage.h: No such file or directory #include &amp;ldquo;FreeImage.h&amp;rdquo; CentOS 7 編譯mnistCUDNN，CuDnn的SAMPLE時出現問題， cp -r /usr/src/cudnn_samples_v8/ $HOME cd $HOME/cudnn_samples_v8/mnistCUDNN # make clean &amp;amp;&amp;amp; make 錯誤訊息： test.c:1:23: fatal error: FreeImage.h: No such file or directory #include &amp;quot;FreeImage.h&amp;quot;</description>
    </item>
    
    <item>
      <title>Flexible Multiple-Objective Reinforcement Learning for Chip Placement 閱讀筆記</title>
      <link>https://take72k.github.io/EDA/MORLPlace/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://take72k.github.io/EDA/MORLPlace/</guid>
      <description>用於晶片擺置的靈活性多目標強化學習 link to paper 為了EDA Workshop看的。 本篇的亮點\貢獻： 提出彈性多目標的強化學習(flexible multiple-objective reinforcement learning, MORL)</description>
    </item>
    
  </channel>
</rss>
